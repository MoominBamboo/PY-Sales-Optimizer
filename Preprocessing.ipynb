{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSEMfRk5Cm9A",
        "outputId": "77d5994a-9994-4970-a53b-79f738a0a8ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import silhouette_score\n",
        "import statsmodels.api\n",
        "import statsmodels.formula.api as smf\n",
        "from scipy import stats\n",
        "from scipy.spatial.distance import cdist\n",
        "#from yellowbrick.cluster import SilhouetteVisualizer\n",
        "\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "seed = 100\n",
        "\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Pakistan Largest Ecommerce Dataset.csv\");"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(axis=0,how='all',inplace=True)\n",
        "df.dropna(axis=1,how='all',inplace=True)\n",
        "df=df.drop([\"sales_commission_code\"],axis=1)\n",
        "df=df.dropna(axis=0,how=\"any\")\n",
        "\n",
        "df['status_new'] = df['status']\n",
        "df['status_new'] = df['status_new'].replace(['order_refunded', 'refund'],'refunded')\n",
        "df['status_new'] = df['status_new'].replace(['complete', 'closed'],'completed')\n",
        "df['status_new'] = df['status_new'].replace(['paid','received','cod',\"exchange\"],'processing')\n",
        "df['status_new'] = df['status_new'].replace(['holded','pending_paypal','payment_review'],'pending')\n",
        "\n",
        "df['grand_item']=df[\"price\"]*df[\"qty_ordered\"] - df[\"discount_amount\"]\n",
        "test=df.groupby([\"increment_id\"]).agg({\"grand_item\":\"sum\",\"grand_total\":\"mean\",\"item_id\":\"count\"})\n",
        "\n",
        "df=df[df[\"price\"]>0]\n",
        "df=df[df[\"grand_total\"]>0]\n",
        "df=df[df[\"discount_amount\"]>=0]\n",
        "\n",
        "test=df.groupby([\"increment_id\"]).agg({\"grand_item\":\"sum\",\"grand_total\":\"mean\",\"item_id\":\"count\"})\n",
        "\n",
        "test2=test[test[\"grand_item\"] - test[\"grand_total\"]==0]\n",
        "\n",
        "dele=[]\n",
        "for incid in df[\"increment_id\"]:\n",
        "  dele.append(incid in test2.index)\n",
        "\n",
        "dft=df.loc[dele]\n",
        "df=dft\n",
        "\n",
        "df['discount_rate'] = (df['discount_amount']/(df[\"price\"]*df[\"qty_ordered\"])* 100).round(2)\n",
        "\n",
        "df.category_name_1.fillna('\\\\N',inplace=True)\n",
        "df.category_name_1.replace('\\\\N',\"Others\",inplace=True)\n",
        "\n",
        "\n",
        "df[\"BI Status\"]=df[\"BI Status\"].replace(to_replace=['#REF!'],value=[\"Net\"])\n",
        "df['BIstatus_num'] = df['BI Status']\n",
        "df['BIstatus_num'] = df['BIstatus_num'].replace(['Net'], 1)\n",
        "df['BIstatus_num'] = df['BIstatus_num'].replace(['Valid'], 0)\n",
        "df['BIstatus_num'] = df['BIstatus_num'].replace(['Gross'], -1)\n",
        "\n",
        "df['status_new'] = df['status']\n",
        "df['status_new'] = df['status_new'].replace(['order_refunded', 'refund'],'refunded')\n",
        "df['status_new'] = df['status_new'].replace(['complete', 'closed'],'completed')\n",
        "df['status_new'] = df['status_new'].replace(['paid','received','cod',\"exchange\"],'processing')\n",
        "df['status_new'] = df['status_new'].replace(['holded','pending_paypal','payment_review'],'pending')\n",
        "\n",
        "df['payment_method'].replace(['Easypay_MA','easypay_voucher'],'Easypay',inplace=True)\n",
        "df['payment_method'].replace(['jazzwallet','jazzvoucher'],'Jazz',inplace=True)\n",
        "df['payment_method'].replace(['customercredit','ublcreditcard'],'Credit',inplace=True)\n",
        "df['payment_method'].replace(['internetbanking'],'bankalfalah',inplace=True)\n",
        "\n",
        "df['Working Date2'] = pd.to_datetime(df['Working Date'])\n",
        "base = df['Working Date2'].max()\n",
        "df['Date'] = df['Working Date2'].apply(lambda x: x.date())\n",
        "df['Customer_Since_Date'] = df.groupby('Customer ID')['Date'].transform(min)\n",
        "df['Lifetime'] = (base.date() - df['Customer_Since_Date']).astype('timedelta64[D]') + 1\n"
      ],
      "metadata": {
        "id": "0zf1hjNWC6iB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for RFM models\n",
        "df=df[(df[\"status_new\"]==\"completed\")|(df[\"status_new\"]==\"processing\")]\n",
        "\n",
        "T1=df.groupby([\"Customer ID\"]).agg({\"increment_id\":\"count\"})\n",
        "m1=T1[\"increment_id\"].mean()\n",
        "s1=T1[\"increment_id\"].std()\n",
        "A1=T1[T1[\"increment_id\"]<=m1+3*s1]\n",
        "a1=A1.index\n",
        "lis=[]\n",
        "for id in df[\"Customer ID\"]:\n",
        "  lis.append(id in a1)\n",
        "\n",
        "df1=df.iloc[lis]\n",
        "\n",
        "\n",
        "# price, qty_ordered, discount_rate (for Monetary)\n",
        "zpmax=df[\"price\"].mean()+3*df[\"price\"].std()\n",
        "zpmin=df[\"price\"].mean()-3*df[\"price\"].std()\n",
        "data=df1[(df1[\"price\"]>=zpmin) & (df1[\"price\"]<=zpmax)]\n",
        "\n",
        "zqmax=data[\"qty_ordered\"].mean()+3*data[\"qty_ordered\"].std()\n",
        "zqmin=data[\"qty_ordered\"].mean()-3*data[\"qty_ordered\"].std()\n",
        "data=data[(data[\"qty_ordered\"]>=zqmin) & (data[\"qty_ordered\"]<=zqmax)]\n",
        "\n",
        "zdmax=data[\"discount_rate\"].mean()+3*data[\"discount_rate\"].std()\n",
        "zdmin=data[\"discount_rate\"].mean()-3*data[\"discount_rate\"].std()\n",
        "data=data[(data[\"discount_rate\"]>=zdmin) & (data[\"discount_rate\"]<=zdmax)]\n",
        "\n"
      ],
      "metadata": {
        "id": "KAsjgygAEZn6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RFM-scores:\n",
        "# Absolute table\n",
        "# Recency: Days since last purchase\n",
        "\n",
        "data['Working Date'] = pd.to_datetime(data['Working Date'])\n",
        "base = data['Working Date'].max()\n",
        "data['Date'] = data['Working Date'].apply(lambda x: x.date())\n",
        "data['Most_Recent_Purchase'] = data.groupby('Customer ID')['Date'].transform(max)\n",
        "data['Recency'] = (base.date() - data['Most_Recent_Purchase']).astype('timedelta64[D]')\n",
        "\n",
        "# Frequency: Total number of purchases\n",
        "data['Frequency'] = data.groupby('Customer ID')['increment_id'].transform('nunique')\n",
        "\n",
        "# Monetary: Total amount spend\n",
        "data['Monetary'] = data.groupby('Customer ID')['grand_item'].transform('sum')\n",
        "\n",
        "#RFM table\n",
        "RFM_abs= data[['Customer ID', 'Recency', 'Frequency', 'Monetary']].drop_duplicates()\n",
        "RFM_plot=RFM_abs.set_index(\"Customer ID\")"
      ],
      "metadata": {
        "id": "y7pX7gzB97_z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RFM table relative\n",
        "data['Working Date3'] = pd.to_datetime(data['Working Date'])\n",
        "base = data['Working Date3'].max()\n",
        "data['Date'] = data['Working Date3'].apply(lambda x: x.date())\n",
        "data['Customer_Since_Date'] = data.groupby('Customer ID')['Date'].transform(min)\n",
        "data['Lifetime'] = (base.date() - data['Customer_Since_Date']).astype('timedelta64[D]') + 1\n",
        "\n",
        "data['Rel. Frequency'] = data['Frequency'] / (data['Lifetime']) * 100\n",
        "RFM_rel= data[['Customer ID', 'Recency', 'Rel. Frequency', 'Monetary']].drop_duplicates()\n",
        "RFM_plot2=RFM_rel.set_index(\"Customer ID\")"
      ],
      "metadata": {
        "id": "EPbvw7Ey99Lk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RFM table frequency score\n",
        "RFM_score_abs=RFM_abs.copy()\n",
        "RFM_score_abs[\"Recency\"]=pd.qcut(RFM_score_abs[\"Recency\"],5,labels=[5,4,3,2,1])\n",
        "RFM_abs[\"Frequency\"][RFM_abs[\"Frequency\"]!=1].value_counts(normalize=True)\n",
        "RFM_score_abs[\"Frequency\"]=pd.cut(RFM_score_abs[\"Frequency\"],bins=[0,1,2,3,6,60],labels=[1,2,3,4,5])\n",
        "RFM_score_abs[\"Monetary\"]=pd.qcut(RFM_score_abs[\"Monetary\"],5,labels=[1,2,3,4,5])\n",
        "RFM_score_abs_plot= RFM_score_abs.set_index(\"Customer ID\")"
      ],
      "metadata": {
        "id": "tPRhcAXZ-B8X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RFM table score, rel. frequency\n",
        "RFM_score_rel=RFM_rel.copy()\n",
        "RFM_score_rel[\"Recency\"]=pd.qcut(RFM_score_rel[\"Recency\"],5,labels=[5,4,3,2,1])\n",
        "RFM_score_rel[\"Rel. Frequency\"]=pd.qcut(RFM_score_rel[\"Rel. Frequency\"],5,labels=[1,2,3,4,5])\n",
        "RFM_score_rel[\"Monetary\"]=pd.qcut(RFM_score_rel[\"Monetary\"],5,labels=[1,2,3,4,5])\n",
        "RFM_score_rel_plot= RFM_score_rel.set_index(\"Customer ID\")"
      ],
      "metadata": {
        "id": "iUXPcIWe-GO9"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}